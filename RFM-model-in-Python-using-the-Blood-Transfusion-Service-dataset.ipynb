{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author = Alexandros Ioannidis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import functools\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. GLOBAL CONSTANTS  \n",
    "# Application and Run Type constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RUN_TYPE = \"TRAINING\"  # TRAINING , TEST\n",
    "RUN_TITLE = \"BLOOD TRANSFUSION RFM \" + RUN_TYPE + \" DATASET\"\n",
    "# Data File constants\n",
    "CustMasterDSFile = \"transfusion.data.full.txt\";\n",
    "TrainingDSFile = \"transfusion.trainingdata.txt\"; \n",
    "TestDSFile = \"transfusion.testdata.txt\" \n",
    "# Data Frame Column Name constants\n",
    "idColName = \"ID\"; \n",
    "recencyColName = \"Recency (months)\"; \n",
    "frequencyColName = \"Frequency (times)\"; \n",
    "monetaryColName = \"Monetary (cc)\";\n",
    "timesColName = \"Time (months)\"; \n",
    "churnColName = \"Churn (0/1)\";\n",
    "rScoreColName = \"R-Score\"; \n",
    "fScoreColName = \"F-Score\";\n",
    "mScoreColName = \"M-Score\";\n",
    "rfmScoreColName = \"RFM-Score\";\n",
    "# RFM Segmentation Analysis & Score Calculation constants\n",
    "rfmRecencyClusters = 5;\n",
    "rfmFrequencyClusters = 5;\n",
    "rfmMonetaryClusters = 5 \n",
    "# if TRUE, CUSTSEGMMATRICE_LST is used\n",
    "RFM_MATRICES_PROVIDED = True \n",
    "RECENCY = np.zeros((rfmRecencyClusters,3)); RECENCY = [1, 0, 5, 2, 3, 4, 3, 4, 3, 4, 11, 2, 5, 16, 1];\n",
    "FREQUENCY = np.zeros((rfmFrequencyClusters,3)); FREQUENCY = [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 5, 4, 5, 8, 5];\n",
    "MONETARY = np.zeros((rfmMonetaryClusters,3)); MONETARY = [1, 250, 1, 2, 500, 2, 3, 750, 3, 4, 1250, 4, 5, 2000, 5];\n",
    "CUSTSEGMMATRICE_LST = [RECENCY, FREQUENCY, MONETARY]\n",
    "# [print(i) for i in CUSTSEGMMATRICE_LST]\n",
    "# R, F, M coefficients for RFMScore\n",
    "rfmCoefficients = [1, 1, 1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. FUNCTIONS   \n",
    "#### 2.1 BUILT CLUSTER MATRIX FOR AN ATTRIBUTE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will create a Cluster Matrix for the specified Feature column, after having sorted the Feature column accordingly (sortDescending) The Cluster Matrix will describe the StartValue and Score for each cluster ID\n",
    "def createFeatureClusterMatrix(featureColumn, noOfClusters, sortDesc):\n",
    "    featureColumn = featureColumn.sort(reverse=True) # sort the featureColumn in sortDesc order, which orders values in a way that the top most have the highest scores\n",
    "# create a clusterMatrix noOfClusters rows by 3 columns (ClusterID, StartValue, Score).if skipped clusters are encountered (due to a large number of equal values) these rows will be removed and the clusterMatrix will contains less rows than noOfClusters\n",
    "    clusterMatrix = np.zeros(noOfClusters, 3);  tmp_len = len(featureColumn)\n",
    "    clusterElements = round(tmp_len / noOfClusters) # calculate the ideal number of elements per cluster\n",
    "    dataIdx = 1 # declare and initialize an index to iterate through featureColumn\n",
    "    noMoreClustersToProcess = FALSE # declare and initialize a flag to stop processing more clusters\n",
    "    for clusterID in range(1,noOfClusters+1): # create a for loop with an index e.g. clusterID in the range [1:noOfClusters]\n",
    "      # check if we must skip an entire cluster!\n",
    "        if((noMoreClustersToProcess) or (dataIdx > clusterID * clusterElements and clusterID < noOfClusters)):\n",
    "            clusterMatrix[clusterID][1] = -1 # it signals that this row should be deleted!\n",
    "            continue  \n",
    "        clusterMatrix[clusterID][1] = clusterID # define the clusterID of cluster      \n",
    "        startValue = featureColumn[dataIdx] # define the start value of cluster      \n",
    "        if (clusterID < noOfClusters): dataIdx = clusterID * clusterElements # update the dataIdx with the position of the ideal-last element of the clusterID\n",
    "        else: dataIdx = tmp_len\n",
    "        endValue = featureColumn[dataIdx] # retrieve the value of the ideal-last element of the clusterID\n",
    "        if (sortDesc): clusterMatrix[clusterID, 2] = endValue # set the start value for the cluster to endValue or startValue\n",
    "        else: clusterMatrix[clusterID, 2] = startValue\n",
    "        clusterMatrix[clusterID, 3] = noOfClusters - clusterID + 1 # define the score value of cluster with clusterID\n",
    "        # advance the dataIdx as many places as necessary in order to find the first element that will have a differnt value from the last recorded endValue. This\n",
    "        # new different value will be the startValue for the following clusterID\n",
    "        for duplicatesIndx in range(dataIdx,tmp_len):\n",
    "            if (featureColumn[duplicatesIndx] != endValue):\n",
    "                dataIdx = duplicatesIndx; break;\n",
    "        noMoreClustersToProcess = (featureColumn[tmp_len] == endValue) # check if there are no more cluster to process.\n",
    "    clusterMatrix = clusterMatrix[clusterMatrix[:, 1] > 0, ] # remove clusterMatrix rows with negative IDs (they represent skipped clusters)\n",
    "    clusterMatrix = clusterMatrix[order(clusterMatrix[:, 2], clusterMatrix[:, 3], decreasing = FALSE), ] # sort clusterMatrix with column 2 in ascending order (bigger values last, so that featureScore() can start from the last row always)\n",
    "    return clusterMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CALCULATE SCORE FOR AN ATTRIBUTE VALUE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureScore(featureValue, featureClusterMatrix):\n",
    "    retvalue = 0\n",
    "    tmp = (len(featureClusterMatrix)-1)\n",
    "    for clusterId in reversed(range(tmp)):\n",
    "        if (featureValue >= featureClusterMatrix.iloc[featureClusterMatrix.index.get_loc(clusterId) + 1, 1]):\n",
    "            retvalue = featureClusterMatrix.iloc[featureClusterMatrix.index.get_loc(clusterId) + 1, 2];\n",
    "            break;\n",
    "    return(retvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CALCULATE SCORE FOR AN ATTRIBUTE VALUE ### specifically for R-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureRScore(featureValue, featureClusterMatrix):\n",
    "    retvalue = 0\n",
    "    tmp = (len(featureClusterMatrix))\n",
    "    for clusterId in reversed(range(tmp)):\n",
    "        if (featureValue >= featureClusterMatrix.ix[clusterId, 1]):\n",
    "            retvalue = featureClusterMatrix.ix[clusterId, 2];\n",
    "            break;\n",
    "    return(retvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 CALCULATE MOVING AVERAGE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcMovingAverage(v, m):\n",
    "    tmp_len = len(v); \n",
    "    ret_v = [None]*tmp_len\n",
    "    for i in range(tmp_len):\n",
    "    # find the position of the start and last element to summarize\n",
    "        if(i <= m):\n",
    "            startPos = 1 \n",
    "            endPos = i + m\n",
    "        elif (i >= tmp_len - m):\n",
    "            endPos = tmp_len \n",
    "            startPos = i - m\n",
    "        else:\n",
    "            startPos = i - m \n",
    "            endPos = i + m    \n",
    "        sum = 0 # accumulate the elements in range [startPos..endPos]\n",
    "        for j in range(startPos,endPos): \n",
    "            sum = sum + v[j]\n",
    "        #print(sum, endPos - startPos + 1)\n",
    "        ret_v[i] = sum/(endPos - startPos + 1) # find average and store it in new vector\n",
    "    return ret_v "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4  PARTITION CUSTOMER DATA SET TO TRAINING & TEST DATA SETS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partitionCustomerDSToTrainingTestDS(CustMasterDSFile,TrainingDSFile, TestDSFile, RunType): # RUN_TYPE is {\"TRAINING\" | \"TEST\"}\n",
    "    print(\"partitionCustomerDSToTrainingTestDS()\") # print function display header\n",
    "    custMDF = pd.read_csv(CustMasterDSFile, sep=\",\", header = 0)\n",
    "    # The column names can be found in  => data.dtype.names\n",
    "    custMDF = pd.DataFrame(custMDF) # add autonumber column to create user-ids\n",
    "    custMDF.insert(0, idColName, range(len(custMDF)))\n",
    "    trainDF = custMDF[custMDF[idColName] <= 500];\n",
    "    testDF = custMDF[custMDF[idColName] > 500] # split training and test\n",
    "    # store data frames to files\n",
    "    trainDF.to_csv(TrainingDSFile, sep=\",\",index=False)\n",
    "    testDF.to_csv(TestDSFile, sep=',',index=False)\n",
    "    if (RunType == \"TRAINING\"): RunFile = TrainingDSFile # set RunFile\n",
    "    else: RunFile = TestDSFile\n",
    "    return RunFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 RFM DATASET PREPARATION ###  RunFile schema : (ID, Recency, Frequency, Monetary, Time, Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareRFMTCdataset(RunFile):\n",
    "    print(\"prepareRFMTCdataset()\") # print function display header\n",
    "    rfmtcDF = pd.read_csv(RunFile, sep=\",\", header = 0) # read RunFile with header\n",
    "    tmp_len = len(rfmtcDF['ID'])\n",
    "    rfmtcDF = pd.DataFrame(rfmtcDF.iloc[:, 1:6]) # add autonumber column to create user-ids and create the rfmtcDF from the rfmtcDF \n",
    "    rfmtcDF.insert(0, idColName, range(len(rfmtcDF)))\n",
    "    # define appropriate column labels\n",
    "    rfmtcDF.columns = [idColName, recencyColName, frequencyColName, monetaryColName, timesColName, churnColName]\n",
    "    # and 4 blank score columns\n",
    "    rfmtcDF[rScoreColName] = 0\n",
    "    rfmtcDF[fScoreColName] = 0\n",
    "    rfmtcDF[mScoreColName] = 0\n",
    "    rfmtcDF[rfmScoreColName] = 0\n",
    "    return rfmtcDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 CALCULATE & STORE RFM SEGMENTATION MATRICES ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcRFMSegmentationMatrices(rfmtcReadyDF): \n",
    "    print(\"calcRFMSegmentationMatrices()\")\n",
    "    # Logic to create segmentation should be added here If segmentation matrices are provided by customer logic  then load them from CUSTSEGMMATRICE_LST\n",
    "    if not RFM_MATRICES_PROVIDED:   \n",
    "        rfmRecencyClusterMatrix = createFeatureClusterMatrix(rfmtcReadyDF[recencyColName], rfmRecencyClusters, FALSE)\n",
    "        rfmFrequencyClusterMatrix = createFeatureClusterMatrix(rfmtcReadyDF[frequencyColName], rfmFrequencyClusters, TRUE)\n",
    "        rfmMonetaryClusterMatrix = createFeatureClusterMatrix(rfmtcReadyDF[monetaryColName], rfmMonetaryClusters, TRUE)\n",
    "    else:\n",
    "        rfmRecencyClusterMatrix = CUSTSEGMMATRICE_LST[0]; \n",
    "        rfmFrequencyClusterMatrix = CUSTSEGMMATRICE_LST[1]; \n",
    "        rfmMonetaryClusterMatrix = CUSTSEGMMATRICE_LST[2]  \n",
    "    # save the segmentation matrices to external files\n",
    "    # convert Recency to dataframe \n",
    "    rfmRecencyClusterMatrix = np.array(rfmRecencyClusterMatrix);\n",
    "    new_rfmRecencyClusterMatrix = rfmRecencyClusterMatrix.reshape(5,3)\n",
    "    RECENCYdf = pd.DataFrame(new_rfmRecencyClusterMatrix)\n",
    "    # convert Frequency to dataframe\n",
    "    rfmFrequencyClusterMatrix = np.array(rfmFrequencyClusterMatrix)\n",
    "    new_rfmFrequencyClusterMatrix = rfmFrequencyClusterMatrix.reshape(5,3)\n",
    "    FREQUENCYdf = pd.DataFrame(new_rfmFrequencyClusterMatrix)\n",
    "    # convert Monetary to dataframe\n",
    "    rfmMonetaryClusterMatrix = np.array(rfmMonetaryClusterMatrix)\n",
    "    new_rfmMonetaryClusterMatrix = rfmMonetaryClusterMatrix.reshape(5,3)\n",
    "    MONETARYdf = pd.DataFrame(new_rfmMonetaryClusterMatrix)\n",
    "    # write to file \n",
    "    RECENCYdf.to_csv(\"RECENCY_SEGMENTATION_MATRIX.csv\",sep=\",\",index=False,header=False)\n",
    "    FREQUENCYdf.to_csv(\"FREQUENCY_SEGMENTATION_MATRIX.csv\",sep=\",\",index=False,header=False)\n",
    "    MONETARYdf.to_csv(\"MONETARY_SEGMENTATION_MATRIX.csv\",sep=\",\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make my own paste() method for python equivalent to paste() in R ## Start ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_concat(x, sep=\"\"):                                                      \n",
    "    return functools.reduce(lambda x, y: str(x) + sep + str(y), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paste(*lists, sep=\" \", collapse=None):\n",
    "    result = map(lambda x: reduce_concat(x, sep=sep), zip(*lists))\n",
    "    if collapse is not None:\n",
    "        return reduce_concat(result, sep=collapse)\n",
    "    return list(result)\n",
    "                                                                     ## End ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 LOAD RFM SEGMENTATION MATRICES ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadRFMSegmentationMatrices():\n",
    "    print(\"loadRFMSegmentationMatrices()\")\n",
    "    # load the segmentation matrices from the external files\n",
    "    rsm = pd.read_csv(\"RECENCY_SEGMENTATION_MATRIX.csv\", sep=\",\", header = None)\n",
    "    fsm = pd.read_csv(\"FREQUENCY_SEGMENTATION_MATRIX.csv\", sep=\",\", header = None)\n",
    "    msm = pd.read_csv(\"MONETARY_SEGMENTATION_MATRIX.csv\", sep=\",\", header = None)\n",
    "    rsm.columns = [\"Cluster No\", \"Start Value\", \"Score\"]\n",
    "    fsm.columns = [\"Cluster No\", \"Start Value\", \"Score\"]\n",
    "    msm.columns = [\"Cluster No\", \"Start Value\", \"Score\"]\n",
    "    RECENCY = rsm\n",
    "    FREQUENCY = fsm\n",
    "    MONETARY = msm\n",
    "    SEGMMATRICE_LST = [RECENCY, FREQUENCY, MONETARY] # store segmentation matrices to a list\n",
    "    return SEGMMATRICE_LST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 CALCULATE R,F,M SCORES & RFM TOTAL SCORE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rfmScoreCalculation(rfmtcReadyDF, SEGMMATRICE_LST):\n",
    "    print(\"rfmScoreCalculation()\")\n",
    "    tmp_col1 = [None]*len(rfmtcReadyDF.iloc[:,1])\n",
    "    tmp_col2 = [None]*len(rfmtcReadyDF.iloc[:,1])\n",
    "    tmp_col3 = [None]*len(rfmtcReadyDF.iloc[:,1])\n",
    "    # calculate R, F, M feature scores\n",
    "    for idx, obj in rfmtcReadyDF.iterrows():\n",
    "        tmp_col1[idx] = featureRScore(obj[recencyColName], SEGMMATRICE_LST[0])\n",
    "    for idx, obj in rfmtcReadyDF.iterrows():\n",
    "        tmp_col2[idx] = featureScore(obj[frequencyColName], SEGMMATRICE_LST[1])\n",
    "    # replace zeros with 1 \n",
    "    for n,i in enumerate(tmp_col2):\n",
    "        if i==0:\n",
    "            tmp_col2[n]=1\n",
    "    for idx, obj in rfmtcReadyDF.iterrows():\n",
    "        tmp_col3[idx] = featureScore(obj[monetaryColName], SEGMMATRICE_LST[2])\n",
    "    # replace zeros with 1 \n",
    "    for n,i in enumerate(tmp_col3):\n",
    "        if i==0:\n",
    "            tmp_col3[n]=1\n",
    "    # calculate RFM Total score\n",
    "    #rfmtcReadyDF.insert(7, recencyColName, tmp_col1)\n",
    "    rfmtcReadyDF[rScoreColName] = tmp_col1\n",
    "    rfmtcReadyDF[fScoreColName] = tmp_col2\n",
    "    rfmtcReadyDF[mScoreColName] = tmp_col3    \n",
    "    rfmtcReadyDF[rfmScoreColName] = rfmCoefficients[0] * rfmtcReadyDF[rScoreColName] + rfmCoefficients[1] * rfmtcReadyDF[fScoreColName] + rfmCoefficients[2] * rfmtcReadyDF[mScoreColName] \n",
    "    #print(rfmtcReadyDF)\n",
    "    # sort data on all feature scores in desc order\n",
    "    rfmtcReadyDF = rfmtcReadyDF.sort_values(by=[rScoreColName, fScoreColName, mScoreColName], ascending=[False, False, False]) \n",
    "    return rfmtcReadyDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 CALCULATE P[B] & RFM RESPONSE PROBABILITY & STORE RESULTS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculatePB_RespProb(rfmtcScoredDF, m):\n",
    "    print(\"calculatePB_RespProb()\") # m comes from RFMTC training set calculations\n",
    "    # sort data frame with the RFM-Score in descending order RFM-Score desc & R desc & F asc & M asc\n",
    "    rfmtcScoredDF = rfmtcScoredDF.sort_values(by=['RFM-Score', 'Recency (months)', 'Frequency (times)', 'Monetary (cc)'], ascending=[False, False, True, True])\n",
    "    tmp_vector = calcMovingAverage(rfmtcScoredDF[churnColName], m)\n",
    "    #print(tmp_vector)\n",
    "    tmp_df = pd.DataFrame(tmp_vector)\n",
    "    rfmtcScoredDF[\"P[B]\"] = tmp_df\n",
    "    # Calculate RFM Segment Response Probability / select RFM-Score, avg(P[B]) from rfmtcScoredDF group by RFM-Score\n",
    "    g = rfmtcScoredDF.groupby('RFM-Score')\n",
    "    rfmAggrData  = g[['RFM-Score','P[B]']].mean()\n",
    "    rfmAggrData.columns = ['Segment','Response Probability']\n",
    "    # Lookup RFM Customer Response Probabilities from rfmAggrData data frame and fill them into the Validation data frame\n",
    "    tmp_len = len(rfmtcScoredDF.iloc[:,1]) \n",
    "    rfmtcScoredDF = pd.DataFrame(rfmtcScoredDF)\n",
    "    rfmtcScoredDF['RFM Resp Prob'] = 0\n",
    "    #print(rfmtcScoredDF)\n",
    "    for i in range(tmp_len):\n",
    "        x = rfmAggrData.loc[:,'Segment'] == rfmtcScoredDF.ix[i,rfmScoreColName]\n",
    "        rfmtcScoredDF.ix[i,'RFM Resp Prob'] = rfmAggrData.ix[x[x].index[0], 1]        \n",
    "    rfmtcScoredDF.to_csv(\"OUR_RFM_\" + RUN_TYPE + \".csv\", sep=',')    # write data to file\n",
    "    return rfmtcScoredDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MAIN PROGRAM ### ## PART A  convert transaction datasets to RFM-RFMTC customer datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOOD TRANSFUSION RFM TRAINING DATASET\n",
      "-------------------------------\n",
      "partitionCustomerDSToTrainingTestDS()\n",
      "prepareRFMTCdataset()\n",
      "calcRFMSegmentationMatrices()\n",
      "loadRFMSegmentationMatrices()\n",
      "rfmScoreCalculation()\n",
      "calculatePB_RespProb()\n",
      "      ID  Recency (months)  Frequency (times)  Monetary (cc)  Time (months)  \\\n",
      "35    35                 2                  8           2000             28   \n",
      "61    61                 2                  8           2000             35   \n",
      "8      8                 2                  9           2250             22   \n",
      "46    46                 2                  9           2250             36   \n",
      "140  140                 2                  9           2250             74   \n",
      "12    12                 2                 10           2500             28   \n",
      "62    62                 2                 10           2500             49   \n",
      "109  109                 2                 10           2500             64   \n",
      "50    50                 2                 11           2750             46   \n",
      "51    51                 2                 11           2750             46   \n",
      "119  119                 2                 11           2750             79   \n",
      "134  134                 2                 11           2750             88   \n",
      "36    36                 2                 12           3000             47   \n",
      "53    53                 2                 12           3000             52   \n",
      "114  114                 2                 12           3000             82   \n",
      "131  131                 2                 12           3000             95   \n",
      "137  137                 2                 12           3000             98   \n",
      "40    40                 2                 13           3250             53   \n",
      "101  101                 2                 13           3250             76   \n",
      "16    16                 2                 14           3500             48   \n",
      "38    38                 2                 14           3500             57   \n",
      "17    17                 2                 15           3750             49   \n",
      "34    34                 2                 16           4000             64   \n",
      "58    58                 2                 16           4000             81   \n",
      "3      3                 2                 20           5000             45   \n",
      "500  500                 2                 43          10750             86   \n",
      "0      0                 2                 50          12500             98   \n",
      "69    69                 1                  9           2250             51   \n",
      "7      7                 1                 12           3000             35   \n",
      "13    13                 1                 13           3250             47   \n",
      "..   ...               ...                ...            ...            ...   \n",
      "480  480                23                  1            250             23   \n",
      "481  481                23                  1            250             23   \n",
      "482  482                23                  1            250             23   \n",
      "483  483                23                  1            250             23   \n",
      "484  484                23                  1            250             23   \n",
      "468  468                22                  1            250             22   \n",
      "453  453                21                  1            250             21   \n",
      "454  454                21                  1            250             21   \n",
      "455  455                21                  1            250             21   \n",
      "456  456                21                  1            250             21   \n",
      "457  457                21                  1            250             21   \n",
      "458  458                21                  1            250             21   \n",
      "459  459                21                  1            250             21   \n",
      "460  460                21                  1            250             21   \n",
      "461  461                21                  1            250             21   \n",
      "462  462                21                  1            250             21   \n",
      "463  463                21                  1            250             21   \n",
      "464  464                21                  1            250             21   \n",
      "406  406                16                  1            250             16   \n",
      "407  407                16                  1            250             16   \n",
      "408  408                16                  1            250             16   \n",
      "409  409                16                  1            250             16   \n",
      "410  410                16                  1            250             16   \n",
      "411  411                16                  1            250             16   \n",
      "412  412                16                  1            250             16   \n",
      "414  414                16                  1            250             16   \n",
      "415  415                16                  1            250             16   \n",
      "416  416                16                  1            250             16   \n",
      "417  417                16                  1            250             16   \n",
      "418  418                16                  1            250             16   \n",
      "\n",
      "     Churn (0/1)  R-Score  F-Score  M-Score  RFM-Score      P[B]  \\\n",
      "35             1        5        5        5         15  0.777778   \n",
      "61             1        5        5        5         15  0.444444   \n",
      "8              1        5        5        5         15  0.333333   \n",
      "46             0        5        5        5         15  0.333333   \n",
      "140            0        5        5        5         15  0.000000   \n",
      "12             1        5        5        5         15  0.555556   \n",
      "62             0        5        5        5         15  0.333333   \n",
      "109            0        5        5        5         15  0.111111   \n",
      "50             0        5        5        5         15  0.111111   \n",
      "51             1        5        5        5         15  0.222222   \n",
      "119            1        5        5        5         15  0.555556   \n",
      "134            0        5        5        5         15  0.000000   \n",
      "36             1        5        5        5         15  0.777778   \n",
      "53             0        5        5        5         15  0.444444   \n",
      "114            0        5        5        5         15  0.333333   \n",
      "131            0        5        5        5         15  0.222222   \n",
      "137            0        5        5        5         15  0.000000   \n",
      "40             1        5        5        5         15  0.666667   \n",
      "101            1        5        5        5         15  0.555556   \n",
      "16             1        5        5        5         15  0.777778   \n",
      "38             1        5        5        5         15  0.666667   \n",
      "17             1        5        5        5         15  0.777778   \n",
      "34             0        5        5        5         15  0.666667   \n",
      "58             0        5        5        5         15  0.555556   \n",
      "3              1        5        5        5         15  0.571429   \n",
      "500            1        5        5        5         15  0.166667   \n",
      "0              1        5        5        5         15  0.750000   \n",
      "69             0        5        5        5         15  0.222222   \n",
      "7              0        5        5        5         15  0.444444   \n",
      "13             0        5        5        5         15  0.555556   \n",
      "..           ...      ...      ...      ...        ...       ...   \n",
      "480            0        1        1        1          3  0.000000   \n",
      "481            0        1        1        1          3  0.000000   \n",
      "482            0        1        1        1          3  0.000000   \n",
      "483            0        1        1        1          3  0.000000   \n",
      "484            0        1        1        1          3  0.000000   \n",
      "468            1        1        1        1          3  0.111111   \n",
      "453            0        1        1        1          3  0.000000   \n",
      "454            0        1        1        1          3  0.000000   \n",
      "455            0        1        1        1          3  0.000000   \n",
      "456            0        1        1        1          3  0.000000   \n",
      "457            0        1        1        1          3  0.000000   \n",
      "458            0        1        1        1          3  0.000000   \n",
      "459            0        1        1        1          3  0.111111   \n",
      "460            0        1        1        1          3  0.111111   \n",
      "461            0        1        1        1          3  0.111111   \n",
      "462            1        1        1        1          3  0.111111   \n",
      "463            0        1        1        1          3  0.111111   \n",
      "464            0        1        1        1          3  0.111111   \n",
      "406            0        1        1        1          3  0.000000   \n",
      "407            0        1        1        1          3  0.000000   \n",
      "408            0        1        1        1          3  0.000000   \n",
      "409            0        1        1        1          3  0.000000   \n",
      "410            0        1        1        1          3  0.000000   \n",
      "411            0        1        1        1          3  0.000000   \n",
      "412            0        1        1        1          3  0.000000   \n",
      "414            0        1        1        1          3  0.000000   \n",
      "415            0        1        1        1          3  0.000000   \n",
      "416            0        1        1        1          3  0.000000   \n",
      "417            0        1        1        1          3  0.000000   \n",
      "418            0        1        1        1          3  0.000000   \n",
      "\n",
      "     RFM Resp Prob  \n",
      "35        0.431088  \n",
      "61        0.431088  \n",
      "8         0.431088  \n",
      "46        0.431088  \n",
      "140       0.431088  \n",
      "12        0.431088  \n",
      "62        0.431088  \n",
      "109       0.431088  \n",
      "50        0.431088  \n",
      "51        0.431088  \n",
      "119       0.431088  \n",
      "134       0.431088  \n",
      "36        0.431088  \n",
      "53        0.431088  \n",
      "114       0.431088  \n",
      "131       0.431088  \n",
      "137       0.431088  \n",
      "40        0.431088  \n",
      "101       0.431088  \n",
      "16        0.431088  \n",
      "38        0.431088  \n",
      "17        0.431088  \n",
      "34        0.431088  \n",
      "58        0.431088  \n",
      "3         0.431088  \n",
      "500       0.431088  \n",
      "0         0.431088  \n",
      "69        0.431088  \n",
      "7         0.431088  \n",
      "13        0.431088  \n",
      "..             ...  \n",
      "480       0.040272  \n",
      "481       0.040272  \n",
      "482       0.040272  \n",
      "483       0.040272  \n",
      "484       0.040272  \n",
      "468       0.040272  \n",
      "453       0.040272  \n",
      "454       0.040272  \n",
      "455       0.040272  \n",
      "456       0.040272  \n",
      "457       0.040272  \n",
      "458       0.040272  \n",
      "459       0.040272  \n",
      "460       0.040272  \n",
      "461       0.040272  \n",
      "462       0.040272  \n",
      "463       0.040272  \n",
      "464       0.040272  \n",
      "406       0.040272  \n",
      "407       0.040272  \n",
      "408       0.040272  \n",
      "409       0.040272  \n",
      "410       0.040272  \n",
      "411       0.040272  \n",
      "412       0.040272  \n",
      "414       0.040272  \n",
      "415       0.040272  \n",
      "416       0.040272  \n",
      "417       0.040272  \n",
      "418       0.040272  \n",
      "\n",
      "[501 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(RUN_TITLE); print(\"-------------------------------\")\n",
    "## PART B partition customer dataset to training & test datasets\n",
    "RunFileName =  partitionCustomerDSToTrainingTestDS(CustMasterDSFile, TrainingDSFile, TestDSFile,  RUN_TYPE) \n",
    "rfmtcReadyDF = prepareRFMTCdataset(RunFileName) # PART C RFM dataset preparation\n",
    "if (RUN_TYPE == \"TRAINING\"): calcRFMSegmentationMatrices(rfmtcReadyDF) # calculate/load RFM Clustering matrices \n",
    "SEGMMATRICE_LST = loadRFMSegmentationMatrices() # read the segmentation matrices from external files\n",
    "rfmtcScoredDF = rfmScoreCalculation(rfmtcReadyDF, SEGMMATRICE_LST) # calculate R,F,M scores & RFM total score\n",
    "m = 4\n",
    "rfmtcScoredDF = calculatePB_RespProb(rfmtcScoredDF, m) # calculate & RFM response probability & store results\n",
    "print(rfmtcScoredDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
